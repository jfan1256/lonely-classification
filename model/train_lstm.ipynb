{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef689b0d-da11-487b-b34e-cf015b8b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from utils.system import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a386f0e-37b2-437e-b7ea-9908e0f0726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1806171404303208736\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14267973632\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17531785447253545036\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc8af2-bd6f-4a06-b376-d17eaad8f628",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb57e884-46a8-49dc-8b0c-2a6724cb2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(label, prediction):\n",
    "    cm = confusion_matrix(label, prediction)\n",
    "    TP = cm[1, 1]  # True Positives\n",
    "    TN = cm[0, 0]  # True Negatives\n",
    "    FP = cm[0, 1]  # False Positives\n",
    "    FN = cm[1, 0]  # False Negatives\n",
    "    \n",
    "    # Calculate precision and recall for the positive class\n",
    "    precision_pos = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall_pos = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    f1_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos) if (precision_pos + recall_pos) != 0 else 0\n",
    "    \n",
    "    # Calculate precision and recall for the negative class\n",
    "    precision_neg = TN / (TN + FN) if (TN + FN) != 0 else 0\n",
    "    recall_neg = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg) if (precision_neg + recall_neg) != 0 else 0\n",
    "    \n",
    "    # Display in a table\n",
    "    metrics = pd.DataFrame({\n",
    "        'Metric': ['Precision (Positive)', 'Recall (Positive)', 'F1 Score (Positive)',\n",
    "                   'Precision (Negative)', 'Recall (Negative)', 'F1 Score (Negative)'],\n",
    "        'Value': [precision_pos, recall_pos, f1_pos, precision_neg, recall_neg, f1_neg]\n",
    "    })\n",
    "    \n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97701472-7483-4540-a8c5-8c2f627b348a",
   "metadata": {},
   "source": [
    "#### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16da8344-1fc0-4fb8-8d7a-423788cdbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "article = pd.read_csv(get_data() / 'human_annotations_all_8000_overall.csv')\n",
    "art_emb = pd.read_parquet(get_data() / 'bert_article_emb.parquet.brotli')\n",
    "sentence_emb = pd.read_parquet(get_data() / 'bert_sentence_cosine.parquet.brotli')  \n",
    "sent = pd.read_parquet(get_data() / 'bert_sentiment.parquet.brotli')\n",
    "art_cos = pd.read_parquet(get_data() / 'bert_art_cosine.parquet.brotli')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3702d9d4-871c-410e-89b6-b132c82f4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data together\n",
    "merged_emb = (pd.merge(art_emb, sentence_emb, on='id', how='inner')\n",
    "              .merge(sent, on='id', how='inner')\n",
    "              .merge(art_cos, on='id', how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e75df778-6135-4f21-b16e-9f3a2b58ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack article embeddings + sentence embeddings together into one array\n",
    "merged_emb['comb_emb'] = merged_emb.apply(lambda row: [*row['bert_emb_art'], *row['bert_emb_min'], *row['bert_emb_max']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ba7b2-f91a-459d-899a-d96d7e1fab05",
   "metadata": {},
   "source": [
    "#### Out of Sample Train Model (Embedding + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59f6464e-1f06-49c8-ad75-b239303e84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample\n",
    "undersample = merged_emb.sort_values('overall_label')\n",
    "df_class_0 = undersample[undersample['overall_label'] == 0]\n",
    "df_class_1 = undersample[undersample['overall_label'] == 1]\n",
    "n_samples = min(len(df_class_0), len(df_class_1))\n",
    "df_class_0_under = df_class_0.sample(n_samples)\n",
    "df_class_1_under = df_class_1.sample(n_samples)\n",
    "merged_undersample = pd.concat([df_class_0_under, df_class_1_under], axis=0)\n",
    "merged_undersample = merged_undersample.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8f36f42-98ef-4a1a-ba73-f8adce4d78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve values\n",
    "raw_text = merged_undersample['cleaned_article']\n",
    "emb_art = np.stack(merged_undersample['bert_emb_art'].values)\n",
    "emb_sent = np.stack(merged_undersample['bert_emb_max'].values)\n",
    "emb_all = np.stack(merged_undersample['comb_emb'].values)\n",
    "labels = merged_undersample['overall_label']\n",
    "sent_scores = np.array(merged_undersample['sent_score']).reshape(-1, 1)\n",
    "art_cos_sim = np.array(merged_undersample['cosine_sim_art_mean']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f33497f-f6b3-4e41-9928-d4f29372c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "raw_text_data_list = raw_text.tolist()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_texts = tokenizer(raw_text_data_list, padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "data = encoded_texts['input_ids']\n",
    "data = data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d683981-bf6d-4f76-b28a-7083a3d77843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "data_train, data_test, emb_all_train, emb_all_test, emb_art_train, emb_art_test, emb_sent_train, emb_sent_test, sent_train, sent_test, cos_train, cos_test, labels_train, labels_test = train_test_split(\n",
    "    data, \n",
    "    emb_all,\n",
    "    emb_art, \n",
    "    emb_sent,\n",
    "    sent_scores,\n",
    "    art_cos_sim,\n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1a5db-a0aa-4e0e-9a3a-7ce07549d435",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ded8f5eb-d214-4e40-b85e-4fcd75fd793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Define the inputs\n",
    "input_text = Input(shape=(max_len,), name='input_text')\n",
    "input_art_embedding = Input(shape=(emb_art.shape[1],), name='input_art_embedding')\n",
    "input_sent_max_embedding = Input(shape=(emb_sent.shape[1],), name='input_sent_max_embedding')\n",
    "input_sentiment = Input(shape=(1,), name='sentiment_score')\n",
    "input_cosine = Input(shape=(1,), name='cosine_similarity')\n",
    "\n",
    "# Text processing branch\n",
    "embedding_layer = Embedding(len(word_index) + 1, 100, input_length=max_len)(input_text)\n",
    "lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "\n",
    "# First precomputed embedding branch\n",
    "dense_art_embedding_layer = Dense(64, activation='relu')(input_art_embedding)\n",
    "dropout_art_embedding = Dropout(0.5)(dense_art_embedding_layer)\n",
    "\n",
    "# Second precomputed embedding branch\n",
    "dense_sent_max_embedding_layer = Dense(64, activation='relu')(input_sent_max_embedding)\n",
    "dropout_sent_max_embedding = Dropout(0.5)(dense_sent_max_embedding_layer)\n",
    "\n",
    "# Sentiment score branch\n",
    "dense_sentiment_layer = Dense(32, activation='relu')(input_sentiment)\n",
    "dropout_sentiment = Dropout(0.5)(dense_sentiment_layer)\n",
    "\n",
    "# Cosine Similarity score branch\n",
    "dense_cos_layer = Dense(32, activation='relu')(input_cosine)\n",
    "dropout_cos = Dropout(0.5)(dense_cos_layer)\n",
    "\n",
    "# Concatenate LSTM output, both precomputed embeddings, and sentiment score\n",
    "concat_layer = Concatenate()([lstm_layer, dropout_art_embedding, dropout_sent_max_embedding, dropout_sentiment, dropout_cos])\n",
    "batch_norm = BatchNormalization()(concat_layer)\n",
    "dense_layer = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(batch_norm)\n",
    "dropout_dense = Dropout(0.5)(dense_layer)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_dense)\n",
    "\n",
    "# Construct the model\n",
    "model = Model(inputs=[input_text, input_art_embedding, input_sent_max_embedding, input_sentiment, input_cosine], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5dc32-e7ec-4b44-86c6-12942b705e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [data_train, emb_art_train, emb_sent_train, sent_train, cos_train], \n",
    "    labels_train, \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    validation_split=0.10,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5df617af-fc03-43ec-bef0-7bdca9d5cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 3s 68ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_test = model.predict([data_test, emb_art_test, emb_sent_test, sent_test, cos_test])\n",
    "predicted_labels_test = (predictions_test > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a0b0425-b9f5-43fe-b28f-389a3c181b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.741379\n",
      "1     Recall (Positive)  0.516295\n",
      "2   F1 Score (Positive)  0.608696\n",
      "3  Precision (Negative)  0.647059\n",
      "4     Recall (Negative)  0.831190\n",
      "5   F1 Score (Negative)  0.727657\n"
     ]
    }
   ],
   "source": [
    "# Article Embedding + Sentence Embedding + Sentiment + LSTM + 0.001 LR + No ReduceLR\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ca2cd-ced6-4d7a-90aa-37d349ac1d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad5bac-67c5-402a-a910-ea19efc40e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f4bcc-d81b-4fb3-9810-07e4d44752a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50969bf7-3666-4789-bbb7-70e6093da61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533cd19-144e-4019-84cb-1b021372b755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e39884-9f54-4166-808a-b862c0cd38c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20627f5d-2339-407d-b5f4-98d2ca4874c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e230d1-c4f3-4846-b884-b8b6d4abde89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66d3fd-bb0d-4758-92b9-2d1369f44a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5d22f8-7ba8-4a0f-9fd9-18faaa4927bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.655957\n",
      "1     Recall (Positive)  0.855148\n",
      "2   F1 Score (Positive)  0.742424\n",
      "3  Precision (Negative)  0.803318\n",
      "4     Recall (Negative)  0.568792\n",
      "5   F1 Score (Negative)  0.666012\n"
     ]
    }
   ],
   "source": [
    "# All Embedding + Sent Score + 0.001 LR + BERT Tokenizer + BiLSTM + No RL\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5fdcd990-4ff6-487f-81a4-85bc2ace1d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.711480\n",
      "1     Recall (Positive)  0.798305\n",
      "2   F1 Score (Positive)  0.752396\n",
      "3  Precision (Negative)  0.765286\n",
      "4     Recall (Negative)  0.670121\n",
      "5   F1 Score (Negative)  0.714549\n"
     ]
    }
   ],
   "source": [
    "# All Embedding + 0.001 LR + BERT Tokenizer + BiLSTM + No RL\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a118d77a-0767-4541-9eac-1c0e9f8f17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.679947\n",
      "1     Recall (Positive)  0.867797\n",
      "2   F1 Score (Positive)  0.762472\n",
      "3  Precision (Negative)  0.812500\n",
      "4     Recall (Negative)  0.583765\n",
      "5   F1 Score (Negative)  0.679397\n"
     ]
    }
   ],
   "source": [
    "# All Embedding + 0.001 LR + BERT Tokenizer + BiLSTM\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d116d44-cf38-43bc-8076-127775e54594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.771318\n",
      "1     Recall (Positive)  0.682676\n",
      "2   F1 Score (Positive)  0.724295\n",
      "3  Precision (Negative)  0.716692\n",
      "4     Recall (Negative)  0.798635\n",
      "5   F1 Score (Negative)  0.755448\n"
     ]
    }
   ],
   "source": [
    "# Max + Article Embedding + 0.0001 LR\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "024a5be1-8200-401f-8c3f-21f4dc9d1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.685157\n",
      "1     Recall (Positive)  0.783877\n",
      "2   F1 Score (Positive)  0.731200\n",
      "3  Precision (Negative)  0.749004\n",
      "4     Recall (Negative)  0.641638\n",
      "5   F1 Score (Negative)  0.691176\n"
     ]
    }
   ],
   "source": [
    "# Max + Article Embedding + 0.001 LR\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a599b79e-6915-4cab-aba6-fe7fc2b5a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.696466\n",
      "1     Recall (Positive)  0.573630\n",
      "2   F1 Score (Positive)  0.629108\n",
      "3  Precision (Negative)  0.638081\n",
      "4     Recall (Negative)  0.750427\n",
      "5   F1 Score (Negative)  0.689709\n"
     ]
    }
   ],
   "source": [
    "# Max Embedding\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87efae0a-5d53-4a58-9f17-b5099616b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "0  Precision (Positive)  0.647837\n",
      "1     Recall (Positive)  0.899833\n",
      "2   F1 Score (Positive)  0.753319\n",
      "3  Precision (Negative)  0.821958\n",
      "4     Recall (Negative)  0.485965\n",
      "5   F1 Score (Negative)  0.610805\n"
     ]
    }
   ],
   "source": [
    "# All Embedding\n",
    "metric = get_metric(labels_test, predicted_labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lonely",
   "language": "python",
   "name": "lonely"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
