{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "755e556f-f60f-483d-a3f1-74efeac335cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from utils.system import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d530bc6e-12ea-4810-bf94-3dbf1ed7a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(corpus, n=None, ngram_range=(2, 2)):\n",
    "    vec = CountVectorizer(ngram_range=ngram_range, stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    \n",
    "    # Get feature names and their corresponding sum counts\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    \n",
    "    # Sort words by frequency in descending order\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b1f2629-b7ac-4ad1-bd4b-108e5116c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(get_data() / 'clean_data.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd94008b-0b1b-49a2-be39-21b68580dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely = data.loc[data['overall_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "560ea732-5d1b-4bb6-8624-272c42f547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unigrams = get_top_ngrams(lonely['cleaned_article'], n=20, ngram_range=(1, 1))\n",
    "top_bigrams = get_top_ngrams(lonely['cleaned_article'], n=20, ngram_range=(2, 2))\n",
    "top_trigrams = get_top_ngrams(lonely['cleaned_article'], n=20, ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8eefe884-03af-4794-afad-b822daa2dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Bigrams:  [('feel like', 1143), ('don know', 867), ('just want', 456), ('don want', 399), ('feel lonely', 292), ('just feel', 245), ('make friends', 240), ('feels like', 198), ('best friend', 196), ('don think', 196), ('high school', 195), ('don really', 189), ('just don', 181), ('don feel', 157), ('want talk', 147), ('feeling lonely', 135), ('makes feel', 129), ('friends don', 128), ('like just', 123), ('just wish', 115)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 Bigrams: \", top_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04b28565-e3ee-4b70-9ba3-e20ff2b9a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Trigrams:  [('just feel like', 65), ('don know anymore', 63), ('just don know', 62), ('don feel like', 56), ('feel like just', 51), ('make new friends', 43), ('don really know', 42), ('feel like don', 41), ('feel like ve', 40), ('meet new people', 37), ('just want talk', 36), ('don know just', 33), ('don know feel', 31), ('just want feel', 29), ('just feel lonely', 29), ('makes feel like', 27), ('friends feel like', 26), ('play video games', 26), ('feel like going', 25), ('just feels like', 25)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 Trigrams: \", top_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78575d86-4396-44f6-9a1d-a6d186decb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming top_bigrams and top_trigrams have been correctly extracted\n",
    "top_bigrams = [pair[0] for pair in top_bigrams]\n",
    "top_trigrams = [triple[0] for triple in top_trigrams]\n",
    "\n",
    "# Combine bigrams and trigrams\n",
    "top_ngrams = top_bigrams + top_trigrams\n",
    "\n",
    "# Create a new vectorizer that can capture both bigrams and trigrams\n",
    "# Note: We do not restrict the vocabulary this time\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 3), stop_words='english')\n",
    "\n",
    "# Fit and transform your data using the new vectorizer\n",
    "X = vectorizer.fit_transform(data['cleaned_article'])\n",
    "\n",
    "# Filter out only the columns corresponding to the top N-grams\n",
    "filtered_columns = [col for col in vectorizer.get_feature_names_out() if col in top_ngrams]\n",
    "filtered_X = X[:, [vectorizer.vocabulary_[col] for col in filtered_columns]]\n",
    "\n",
    "# Create a DataFrame from the filtered feature matrix\n",
    "ngram_features = pd.DataFrame(filtered_X.toarray(), columns=filtered_columns)\n",
    "new_column_names = [f'n_gram_{i+1}' for i in range(ngram_features.shape[1])]\n",
    "ngram_features.columns = new_column_names\n",
    "ngram_features.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "503c3b8e-f83e-463a-9d76-40ca222628aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_features.to_parquet(get_data() / 'n_gram.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd41345-a0a4-401c-b89b-8ec3668f2e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lonely",
   "language": "python",
   "name": "lonely"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
