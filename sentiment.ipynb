{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76fff26-567b-4e01-8ac2-9284b39a0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "from utils.system import *\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import pipeline, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe061547-b0d7-4864-b46f-f03263c29fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text):\n",
    "    # Tokenize and truncate the text\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Decode to get a truncated string\n",
    "    truncated_text = tokenizer.decode(inputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Perform sentiment analysis\n",
    "    result = sentiment_pipeline(truncated_text)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "sentiment_pipeline = pipeline('sentiment-analysis', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba221fc7-007b-4ba4-878d-21ecf0acacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(get_data() / 'clean_data.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b72cdf-259b-45af-921a-8eb3c5b6bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 602.0481472015381\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data['sent_article'], data['conf_article'] = zip(*data['cleaned_article'].apply(analyze_sentiment))\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be4234da-81c4-46a3-9752-a502fa6b6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sentiment Score\n",
    "data['sent_score'] = data.apply(\n",
    "    lambda row: 1 if row['sent_article'] == 'POSITIVE' and row['conf_article'] > 0.75 else \n",
    "    (-1 if row['sent_article'] == 'NEGATIVE' and row['conf_article'] > 0.75 else 0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74c619ce-6535-45af-80fb-32f2dd29f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['sent_score']].to_parquet(get_data() / 'bert_sentiment.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd695182-de89-4c3b-8f33-f87d0740c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lonely",
   "language": "python",
   "name": "lonely"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
